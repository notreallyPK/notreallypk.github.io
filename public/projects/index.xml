<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Pratik Kokil</title>
    <link>https://notreallypk.github.io/projects/</link>
    <description>Recent content in Projects on Pratik Kokil</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 13 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://notreallypk.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Audio Transcription Tool</title>
      <link>https://notreallypk.github.io/projects/yatt/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://notreallypk.github.io/projects/yatt/</guid>
      <description>&lt;p&gt;Working on learning about &lt;a href=&#34;https://en.wikipedia.org/wiki/Speech_recognition&#34;&gt;ASR&lt;/a&gt; and shipping something cool.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reader - Text To Speech Tool</title>
      <link>https://notreallypk.github.io/projects/read-aloud/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://notreallypk.github.io/projects/read-aloud/</guid>
      <description>&lt;p&gt;Pocket is dead, and speechify costs money. A project to explore if we can run TTS models locally on a phone, and create a great reading experience.&lt;/p&gt;&#xA;&lt;p&gt;Track notes and status &lt;a href=&#34;https://notreallypk.github.io/content/notes/exploring-tts-one.md&#34;&gt;starting here&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Visualizing Geo-Location data using Deck.gl</title>
      <link>https://notreallypk.github.io/projects/geo-spatial-data-viz/</link>
      <pubDate>Fri, 15 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://notreallypk.github.io/projects/geo-spatial-data-viz/</guid>
      <description>&lt;p&gt;As an official submission to VGI-Hackathon 2024, created a tool to visualize spatio-temporal geo-location trip data of VGI-Flexi trips.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/nairjayesh/vgi_hackathon_2024&#34;&gt;GitHub Repo&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Note: The code hasn&amp;rsquo;t been cleaned up after the hackathon. :/&lt;/p&gt;&#xA;&lt;p&gt;Stack used:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Deck.gl (pydeck) - Interactive maps&lt;/li&gt;&#xA;&lt;li&gt;Streamlit - Frontend for the app&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;map-container&#34;&gt;&#xD;&#xA;    &lt;p&gt; here&#39;s a quick demo of the platform &lt;/p&gt; &#xD;&#xA;    &lt;div class=&#34;video-container&#34;&gt; &#xD;&#xA;        &lt;iframe width=&#34;100%&#34; height=&#34;400&#34; src=&#34;https://www.youtube.com/embed/m_lU4CKEvo0&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt; &#xD;&#xA;    &lt;/div&gt; &#xD;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Sensor data fusion: Camera &amp; Radar</title>
      <link>https://notreallypk.github.io/projects/sensor-fusion/</link>
      <pubDate>Mon, 10 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://notreallypk.github.io/projects/sensor-fusion/</guid>
      <description>&lt;p&gt;This was a team project done under supervision of &lt;a href=&#34;https://www.thi.de/&#34;&gt;Technische Hochschule Ingolstadt&lt;/a&gt;. The goal was to perform late-fusion on radar &amp;amp; camerea detections.&lt;/p&gt;&#xA;&lt;p&gt;This was really fun to work on - got to learn about nitty-gritties of model training, evaluation and spatial fusion of detections. I would like to highlight a few sections here from the project.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/nairjayesh/Sensor-Data-Fusion&#34;&gt;Github Repo&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;image-augmentation&#34;&gt;Image Augmentation:&lt;/h3&gt;&#xA;&lt;p&gt;Primary problem when it comes to working on road user data is high levels of data imbalance among different classes, we were working with 6  road user classes with the following distribution.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Reinforcement Learning</title>
      <link>https://notreallypk.github.io/projects/exploring-rl/</link>
      <pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://notreallypk.github.io/projects/exploring-rl/</guid>
      <description>&lt;p&gt;This was initially a project done as part of Principles of Autonomy and Decision Making at &lt;a href=&#34;https://www.thi.de/&#34;&gt;Technische Hochschule Ingolstadt&lt;/a&gt;. The goal was to implement and test Q-Learning and Deep-Q-Learning in a custom environment.&lt;/p&gt;&#xA;&lt;p&gt;Currently, this page serves as a gateway to exploring different RL algorithms on various environments, starting with Value function based methods.&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-q-learning-and-deep-q-learning&#34;&gt;1/ Q-Learning and Deep Q-Learning&lt;/h2&gt;&#xA;&lt;h3 id=&#34;11-the-environment&#34;&gt;1.1/ The Environment:&lt;/h3&gt;&#xA;&lt;p&gt;The custom environment was built on top of frameworks such as Gymnasium and PyGames. It essentially, involved an agent (Pikachu) who had to navigate it&amp;rsquo;s way through a maze toward&amp;rsquo;s the goal state (Ash) while collecting reward&amp;rsquo;s (badges) and avoiding terminal state&amp;rsquo;s (Meowth).&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
